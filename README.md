# S-RAG: Structured RAG for Answering Aggregative Questions

[![TypeScript](https://img.shields.io/badge/TypeScript-5.3+-blue.svg)](https://www.typescriptlang.org/)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A production-ready TypeScript/Node.js implementation of Structured RAG (S-RAG) as described in the paper ["Structured RAG for Answering Aggregative Questions"](https://arxiv.org/abs/2511.08505v1) by Koshorek et al.

## Overview

S-RAG is a novel approach to Retrieval-Augmented Generation (RAG) that transforms unstructured documents into structured databases at ingestion time, then translates natural language queries to SQL at inference time. This approach is **particularly effective for aggregative queries** that require synthesizing information from many documents.

### Key Innovation

Traditional RAG systems retrieve relevant document chunks and feed them to an LLM. S-RAG instead:
1. **Extracts structured data** from documents during ingestion
2. **Stores data in SQL databases** for efficient querying
3. **Translates questions to SQL** at query time
4. **Generates answers** from query results

This approach excels at questions like "What is the average price across all hotels?" or "How many products cost more than $100?" which require aggregating information from multiple documents.

## Features

- **Automatic Schema Generation**: LLM-based schema prediction from sample documents and questions
- **Intelligent Record Extraction**: Extracts structured data from unstructured text using LLMs
- **Text-to-SQL Translation**: Converts natural language questions to SQL queries
- **Natural Language Answers**: Generates human-readable answers from SQL results
- **Evaluation Framework**: Built-in LLM-as-judge metrics (Answer Comparison, Answer Recall)
- **Dual LLM Support**: Works with both OpenAI (GPT-4o) and Anthropic (Claude) models
- **Type-Safe**: Full TypeScript implementation with strict type checking
- **Production-Ready**: Error handling, retry logic, logging, and comprehensive tests

## Quick Start

### Prerequisites

- **Node.js** >= 18.0.0
- **OpenAI API key** and/or **Anthropic API key**

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/learn-srag.git
cd learn-srag

# Install dependencies
npm install

# Configure environment variables
cp .env.example .env
# Edit .env and add your API keys:
# OPENAI_API_KEY=your-key-here
# ANTHROPIC_API_KEY=your-key-here
```

### Run an Example

```bash
# Try the hotels example
npm run example:hotels

# Try the world cup example
npm run example:worldcup

# Try the custom corpus template
npm run example:custom
```

**ðŸ’¡ Want to use your own data?** See the **[Data Preparation Guide](docs/data-preparation.md)** for tips on structuring documents and questions for optimal results.

### Programmatic Usage

```typescript
import { LLMClient } from './llm/llm-client';
import { SchemaPredictor } from './ingestion/schema-predictor';
import { RecordExtractor } from './ingestion/record-extractor';
import { DatabaseManager } from './database/database-manager';
import { TextToSQL } from './inference/text-to-sql';
import { AnswerGenerator } from './inference/answer-generator';

// Initialize
const llmClient = new LLMClient(process.env.OPENAI_API_KEY);

// 1. Predict schema from sample documents and questions
const predictor = new SchemaPredictor(llmClient);
const schema = await predictor.predictSchema(sampleDocs, sampleQuestions);

// 2. Extract records from all documents
const extractor = new RecordExtractor(llmClient);
const records = await extractor.batchExtract(documents, schema);

// 3. Store in database
const db = new DatabaseManager('data/databases/mydata.db');
db.createTableFromSchema(schema, 'records');
db.insertRecords(records, 'records');

// 4. Query with natural language
const translator = new TextToSQL(llmClient);
const sql = await translator.translate(question, schema, stats, 'records');
const results = db.executeQuery(sql);

// 5. Generate natural language answer
const generator = new AnswerGenerator(llmClient);
const answer = await generator.generateAnswer(question, results, sql);
console.log(answer);
```

## Architecture

S-RAG operates in two distinct phases:

### Ingestion Phase (Offline)

```
Documents + Questions â†’ Schema Prediction â†’ Record Extraction â†’ SQL Database
```

1. **Schema Prediction**: Analyze sample documents and questions to generate a JSON schema
2. **Record Extraction**: Extract structured records from all documents using the schema
3. **Database Creation**: Store records in SQLite with calculated statistics

### Inference Phase (Online)

```
Question â†’ Text-to-SQL â†’ Query Execution â†’ Answer Generation â†’ Natural Language Answer
```

1. **Text-to-SQL**: Translate natural language question to SQL query
2. **Query Execution**: Execute SQL on the structured database
3. **Answer Generation**: Convert query results to natural language answer

## Project Structure

```
learn-srag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/           # Schema prediction & record extraction
â”‚   â”‚   â”œâ”€â”€ schema-predictor.ts
â”‚   â”‚   â”œâ”€â”€ record-extractor.ts
â”‚   â”‚   â””â”€â”€ statistics-calculator.ts
â”‚   â”œâ”€â”€ inference/           # Text-to-SQL & answer generation
â”‚   â”‚   â”œâ”€â”€ text-to-sql.ts
â”‚   â”‚   â”œâ”€â”€ query-executor.ts
â”‚   â”‚   â””â”€â”€ answer-generator.ts
â”‚   â”œâ”€â”€ evaluation/          # Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ evaluator.ts
â”‚   â”‚   â””â”€â”€ metrics.ts
â”‚   â”œâ”€â”€ database/            # Database management
â”‚   â”‚   â””â”€â”€ database-manager.ts
â”‚   â”œâ”€â”€ llm/                 # LLM client wrapper
â”‚   â”‚   â””â”€â”€ llm-client.ts
â”‚   â”œâ”€â”€ models/              # Type definitions & data models
â”‚   â”‚   â”œâ”€â”€ schema.ts
â”‚   â”‚   â”œâ”€â”€ record.ts
â”‚   â”‚   â””â”€â”€ types.ts
â”‚   â””â”€â”€ utils/               # Utilities
â”‚       â”œâ”€â”€ config.ts
â”‚       â”œâ”€â”€ logger.ts
â”‚       â””â”€â”€ helpers.ts
â”œâ”€â”€ examples/                # Usage examples
â”‚   â”œâ”€â”€ hotels-example.ts
â”‚   â”œâ”€â”€ worldcup-example.ts
â”‚   â””â”€â”€ custom-corpus-example.ts
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ datasets/           # Example datasets
â”‚   â”‚   â”œâ”€â”€ hotels/
â”‚   â”‚   â””â”€â”€ worldcup/
â”‚   â”œâ”€â”€ databases/          # SQLite databases
â”‚   â””â”€â”€ schemas/            # Saved schemas
â”œâ”€â”€ tests/                  # Test files
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ prompts/                # LLM prompt templates
â””â”€â”€ scripts/                # Utility scripts
```

## Development

### Build and Test

```bash
# Build the project
npm run build

# Run tests
npm test

# Run tests with UI
npm run test:ui

# Run tests with coverage
npm run test:coverage

# Type checking
npm run typecheck

# Lint code
npm run lint

# Format code
npm run format
```

### Development Mode

```bash
# Watch mode with auto-reload
npm run dev
```

## Performance Metrics

Based on our testing with the hotels and world cup examples:

### Speed
- **Schema generation**: 2-4 minutes (4 iterations of refinement)
- **Record extraction**: 1-2 seconds per document
- **Query answering**: 3-8 seconds end-to-end
- **Text-to-SQL**: 1-3 seconds

### Accuracy
- **Answer Comparison**: >0.70 on benchmark datasets
- **Answer Recall**: >0.65 on benchmark datasets
- **SQL generation success rate**: >85%

## Technology Stack

- **Language**: TypeScript 5.3+
- **Runtime**: Node.js 18+
- **Database**: SQLite (better-sqlite3)
- **LLM APIs**: OpenAI (GPT-4o), Anthropic (Claude)
- **Testing**: Vitest
- **Linting**: ESLint
- **Formatting**: Prettier
- **Build**: TypeScript Compiler

## Documentation

- **[Data Preparation Guide](docs/data-preparation.md)** - How to prepare documents and questions for ingestion
- **[Quickstart Guide](docs/quickstart.md)** - Step-by-step tutorial
- **[Architecture Guide](docs/architecture.md)** - System design and component overview
- **[Evaluation Guide](docs/evaluation.md)** - Metrics and benchmarking

## Examples

### Hotels Example
Demonstrates a complete S-RAG workflow with hotel data:
- 5 hotel documents with varying formats
- Questions about pricing, ratings, amenities
- Aggregative queries (average prices, total capacity)

```bash
npm run example:hotels
```

### World Cup Example
Sports data with match reports:
- 5 World Cup match reports
- Complex nested data (scores, statistics)
- Aggregative questions across matches

```bash
npm run example:worldcup
```

### Custom Corpus Template
A template for your own data:
- Step-by-step instructions
- Customizable configuration
- Example data structure

```bash
npm run example:custom
```

## Use Cases

S-RAG is ideal for:

- **Product catalogs**: "What's the average price of laptops with 16GB RAM?"
- **Financial documents**: "How many companies had revenue over $1B?"
- **Research papers**: "What methods were used in papers about transformers?"
- **Customer reviews**: "What's the average rating for products under $50?"
- **Sports statistics**: "Which teams scored more than 3 goals?"
- **Healthcare records**: "How many patients improved after treatment?"

Any domain where you need to **aggregate information from multiple unstructured documents**.

## Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes with tests
4. Run the test suite
5. Submit a pull request

Please ensure:
- All tests pass (`npm test`)
- Code is formatted (`npm run format`)
- No linting errors (`npm run lint`)
- TypeScript compiles (`npm run typecheck`)

## License

MIT License - see [LICENSE](LICENSE) file for details.

## References

- **Original Paper**: Koshorek et al., "Structured RAG for Answering Aggregative Questions" (arXiv:2511.08505v1)
- **Datasets**: [AI21 Labs Aggregative Questions](https://huggingface.co/datasets/ai21labs/aggregative_questions)

## Citation

If you use this implementation in your research, please cite the original paper:

```bibtex
@article{koshorek2025structured,
  title={Structured RAG for Answering Aggregative Questions},
  author={Koshorek, Omri and others},
  journal={arXiv preprint arXiv:2511.08505},
  year={2025}
}
```

## Acknowledgments

This implementation is based on the S-RAG paper by Koshorek et al. and aims to provide a production-ready, type-safe implementation for the TypeScript/Node.js ecosystem.

## Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/learn-srag/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/learn-srag/discussions)

---

Made with TypeScript and Node.js
